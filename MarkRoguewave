import netCDF4
import numpy as np
import datetime
import calendar

# Configuration parameters
stn = '067'
dataset = 'archive'
deploy = '17'
start_date = '05/01/2008 00:00'
end_date = '05/31/2008 23:59'

# Helper functions for date conversion
def get_unix_timestamp(human_time, date_format="%m/%d/%Y %H:%M"):
    return int(calendar.timegm(datetime.datetime.strptime(human_time, date_format).timetuple()))

def get_human_timestamp(unix_timestamp, date_format="%m/%d/%Y %H:%M:%S"):
    return datetime.datetime.utcfromtimestamp(int(unix_timestamp)).strftime(date_format)

# Load the dataset
data_url = f'http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/{stn}p1/{stn}p1_d{deploy}.nc'
nc = netCDF4.Dataset(data_url)
nc.set_auto_mask(False)

# Read necessary variables
waveHs = nc.variables['waveHs'][:]  # Significant wave height
zdisp = nc.variables['xyzZDisplacement'][:]  # Z-axis displacement
sampling_rate_hz = nc.variables['xyzSampleRate'][:] # Sample rate for Z-axis displacement

# Assuming the start and end UNIX timestamps are correctly calculated
analysis_start_unix = get_unix_timestamp(start_date)
analysis_end_unix = get_unix_timestamp(end_date)

# Calculate the number of seconds per record if each record represents a 30-minute block
seconds_per_record = 1800  # 30 minutes in seconds

# Calculate the total number of records that should be analyzed based on the analysis period
total_analysis_seconds = analysis_end_unix - analysis_start_unix
total_records_to_analyze = total_analysis_seconds // seconds_per_record

# Adjust the rogue wave detection function to consider only the analysis period
def find_rogue_waves_within_period(waveHs, zdisp, sampling_rate_hz, analysis_start_unix, total_records_to_analyze):
    rogue_wave_events = []
    for i in range(total_records_to_analyze):
        # Calculate the actual start second for this record based on sampling rate
        start_sec = i * seconds_per_record * sampling_rate_hz
        if start_sec >= len(zdisp):
            break  # Break if we exceed the length of zdisp
        current_waveHs = waveHs[i]

        for sec_offset in range(0, seconds_per_record):
            sec_index = int(start_sec + sec_offset * sampling_rate_hz)
            if sec_index >= len(zdisp):
                break  # Break if we exceed the length of zdisp
            if zdisp[sec_index] > 2 * current_waveHs:
                # Convert from seconds offset within analysis period to actual UNIX timestamp
                event_time_unix = analysis_start_unix + i * seconds_per_record + sec_offset
                rogue_wave_events.append((get_human_timestamp(event_time_unix, "%m/%d/%Y %H:%M:%S"), current_waveHs, zdisp[sec_index]))
                break  # Consider first detection within the block and move to the next
    return rogue_wave_events


# Use this function to find rogue waves
rogue_wave_events = find_rogue_waves_within_period(waveHs, zdisp, sampling_rate_hz, analysis_start_unix, total_records_to_analyze)

# Print detected rogue wave events
for event in rogue_wave_events:
    print(f"Rogue wave detected at {event[0]} with significant wave height {event[1]:.2f} m and wave height {event[2]:.2f} m")




nc.close()
