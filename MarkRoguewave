!pip install netCDF4
import netCDF4
import numpy as np
import datetime
import calendar

# Configuration parameters
stn = '067'
deploy = '17'
start_date = '05/01/2008 00:00'  # MM/DD/YYYY HH:MM
duration = 30  # Duration in days

# Convert to unix timestamp
def get_unix_timestamp(human_time,dateFormat):
    unix_timestamp = int(calendar.timegm(datetime.datetime.strptime(human_time, dateFormat).timetuple()))
    return unix_timestamp

# Convert to human readable timestamp
def get_human_timestamp(unix_timestamp, dateFormat):
    human_timestamp = datetime.datetime.utcfromtimestamp(int(unix_timestamp)).strftime(dateFormat)
    return human_timestamp

# Load dataset
data_url = f'http://thredds.cdip.ucsd.edu/thredds/dodsC/cdip/archive/{stn}p1/{stn}p1_d{deploy}.nc'
nc = netCDF4.Dataset(data_url)
nc.set_auto_mask(False)

# Extracting variables
time_var = nc.variables['waveTime'][:]  # Assuming this is in UNIX timestamp format
waveHs = nc.variables['waveHs'][:]
start_time = nc.variables['xyzStartTime'][:].item()
sample_rate = nc.variables['xyzSampleRate'][:].item()
WaveHeight = nc.variables['xyzZDisplacement'][:]
filter_delay = nc.variables['xyzFilterDelay'] 
end_time = start_time + (len(WaveHeight) / sample_rate)

# Calculate timestamps for each data point
data_start = get_human_timestamp(start_time - filter_delay[0],"%m/%d/%Y %H:%M:%S")
data_end = get_human_timestamp(end_time - filter_delay[0],"%m/%d/%Y %H:%M:%S")

# Calculate UNIX timestamps for analysis period
unix_start = get_unix_timestamp(start_date,"%m/%d/%Y %H:%M")
unix_end = unix_start + (duration * 24 * 60 * 60)  # Convert duration to seconds

# Calculate sub-second sample times
sample_time = np.arange((start_time - filter_delay[0]), end_time - filter_delay[0],(1/(sample_rate)))

# Finding indices for the analysis period
start_index = np.searchsorted(sample_time, unix_start)
end_index = np.searchsorted(sample_time, unix_end)

# Filter the data for the specified time range
filtered_wave_heights = WaveHeight[start_index:end_index]
filtered_timestamps = sample_time[start_index:end_index]

# Convert 'time_var' to seconds since the start to align with 'filtered_timestamps'
time_var_seconds = (time_var - time_var[0])

# Convert 'filtered_timestamps' to seconds since the start of 'time_var' for direct comparison
filtered_timestamps_seconds = filtered_timestamps - time_var[0]

# For each 'filtered_timestamp', find the index of the last 'waveTime' that is less than or equal to it
# This finds the correct 'waveHs' interval for each high-resolution timestamp
waveHs_indices = np.searchsorted(time_var_seconds, filtered_timestamps_seconds, side='right') - 1
waveHs_indices = np.clip(waveHs_indices, 0, len(waveHs) - 1)  # Ensure indices are within bounds

# Comparing each 'WaveHeight' against twice the corresponding 'waveHs'
is_rogue_wave = filtered_wave_heights > 2 * waveHs[waveHs_indices]
rogue_timestamps = filtered_timestamps[is_rogue_wave]
rogue_wave_heights = filtered_wave_heights[is_rogue_wave]
rogue_waveHs = waveHs[waveHs_indices][is_rogue_wave]

print("Rogue wave events detected within the specified period:")
for i in range(len(rogue_timestamps)):
    precise_timestamp = get_human_timestamp(rogue_timestamps[i], "%Y-%m-%d %H:%M:%S")
    print(f"Rogue wave detected at {precise_timestamp} with significant wave height {rogue_waveHs[i]:.2f} m and wave height {rogue_wave_heights[i]:.2f} m")

